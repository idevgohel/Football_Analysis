{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP7eUP968aJzTNNMP8VpGEv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"source":["from IPython import get_ipython\n","from IPython.display import display\n","\n","from typing import Generator, Iterable, List, TypeVar\n","\n","import numpy as np\n","import supervision as sv\n","import torch\n","import umap\n","from sklearn.cluster import KMeans\n","from tqdm import tqdm\n","from transformers import AutoProcessor, SiglipVisionModel\n","\n","# Define a generic type variable for type hinting\n","V = TypeVar(\"V\")\n","\n","# Path to the pretrained SigLip model from Hugging Face\n","SIGLIP_MODEL_PATH = 'google/siglip-base-patch16-224'"],"cell_type":"code","metadata":{"id":"2RJQxbYzn2_X"},"execution_count":null,"outputs":[]},{"source":["def create_batches(\n","    sequence: Iterable[V], batch_size: int\n",") -> Generator[List[V], None, None]:\n","    \"\"\"\n","    Generate batches from a sequence with a specified batch size.\n","\n","    Args:\n","        sequence (Iterable[V]): The input sequence to be batched.\n","        batch_size (int): The size of each batch.\n","\n","    Yields:\n","        Generator[List[V], None, None]: A generator yielding batches of the input\n","            sequence.\n","    \"\"\"\n","    # Ensure batch size is at least 1\n","    batch_size = max(batch_size, 1)\n","    current_batch = []\n","\n","    # Iterate over each element in the sequence\n","    for element in sequence:\n","        # If current batch reaches desired batch size, yield it and reset\n","        if len(current_batch) == batch_size:\n","            yield current_batch\n","            current_batch = []\n","        # Append current element to the batch\n","        current_batch.append(element)\n","\n","    # Yield any remaining elements as the last batch\n","    if current_batch:\n","        yield current_batch"],"cell_type":"code","metadata":{"id":"VSv1Zwfyn3cb"},"execution_count":null,"outputs":[]},{"source":["class TeamClassifier:\n","    \"\"\"\n","    A classifier that uses a pre-trained SiglipVisionModel for feature extraction,\n","    UMAP for dimensionality reduction, and KMeans for clustering.\n","    \"\"\"\n","    def __init__(self, device: str = 'cpu', batch_size: int = 32):\n","        \"\"\"\n","        Initialize the TeamClassifier with device and batch size.\n","\n","        Args:\n","            device (str): The device to run the model on ('cpu' or 'cuda').\n","            batch_size (int): The batch size for processing images.\n","        \"\"\"\n","        self.device = device\n","        self.batch_size = batch_size\n","\n","        # Load the pre-trained Siglip vision model and move it to the specified device\n","        self.features_model = SiglipVisionModel.from_pretrained(\n","            SIGLIP_MODEL_PATH).to(device)\n","\n","        # Initialize the processor for image preprocessing\n","        self.processor = AutoProcessor.from_pretrained(SIGLIP_MODEL_PATH)\n","\n","        # Initialize UMAP for reducing feature dimensions to 3 components\n","        self.reducer = umap.UMAP(n_components=3)\n","\n","        # Initialize KMeans clustering model with 2 clusters\n","        self.cluster_model = KMeans(n_clusters=2)\n","\n","    def extract_features(self, crops: List[np.ndarray]) -> np.ndarray:\n","        \"\"\"\n","        Extract features from a list of image crops using the pre-trained\n","        SiglipVisionModel.\n","\n","        Args:\n","            crops (List[np.ndarray]): List of image crops.\n","\n","        Returns:\n","            np.ndarray: Extracted features as a numpy array.\n","        \"\"\"\n","        # Convert OpenCV images to PIL images for processing\n","        crops = [sv.cv2_to_pillow(crop) for crop in crops]\n","\n","        # Create batches of images for efficient processing\n","        batches = create_batches(crops, self.batch_size)\n","        data = []\n","\n","        # Disable gradient calculation for inference\n","        with torch.no_grad():\n","            # Iterate over batches with progress bar\n","            for batch in tqdm(batches, desc='Embedding extraction'):\n","                # Process images and prepare tensors on the device\n","                inputs = self.processor(\n","                    images=batch, return_tensors=\"pt\").to(self.device)\n","\n","                # Extract features from the model\n","                outputs = self.features_model(**inputs)\n","\n","                # Compute mean pooling of the last hidden state as embeddings\n","                embeddings = torch.mean(outputs.last_hidden_state, dim=1).cpu().numpy()\n","\n","                # Collect embeddings from all batches\n","                data.append(embeddings)\n","\n","        # Concatenate all batch embeddings into one array\n","        return np.concatenate(data)\n","\n","    def fit(self, crops: List[np.ndarray]) -> None:\n","        \"\"\"\n","        Fit the classifier model on a list of image crops.\n","\n","        Args:\n","            crops (List[np.ndarray]): List of image crops.\n","        \"\"\"\n","        # Extract feature embeddings from crops\n","        data = self.extract_features(crops)\n","\n","        # Apply UMAP dimensionality reduction\n","        projections = self.reducer.fit_transform(data)\n","\n","        # Fit KMeans clustering on reduced projections\n","        self.cluster_model.fit(projections)\n","\n","    def predict(self, crops: List[np.ndarray]) -> np.ndarray:\n","        \"\"\"\n","        Predict the cluster labels for a list of image crops.\n","\n","        Args:\n","            crops (List[np.ndarray]): List of image crops.\n","\n","        Returns:\n","            np.ndarray: Predicted cluster labels.\n","        \"\"\"\n","        # Return empty array if input list is empty\n","        if len(crops) == 0:\n","            return np.array([])\n","\n","        # Extract feature embeddings from crops\n","        data = self.extract_features(crops)\n","\n","        # Project embeddings using fitted UMAP reducer\n","        projections = self.reducer.transform(data)\n","\n","        # Predict cluster labels using trained KMeans model\n","        return self.cluster_model.predict(projections)"],"cell_type":"code","metadata":{"id":"w4yrQHgpn4Fr"},"execution_count":null,"outputs":[]}]}